---
title: "Example Sleuth Analysis"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
---

# Overview

[Sleuth] is an R package and shiny application developed by the Pachter Lab
We have adapted the "[Getting Started with sleuth"][walkthru] so that we can show
how to analyze the datasets that were generated by the staff prior to the start
of this workshop.

[sleuth]: https://pachterlab.github.io/sleuth/about
[walkthru]: https://pachterlab.github.io/sleuth_walkthroughs/trapnell/analysis.html

# Data Retrieval

By now, you have processed each of the FASTQ files generated by each sample
using Kallisto. This will provide you with an output directory per sample
that has data (counts and other metadata) that Kallisto will use for downstream
processing.

We have also processed these data and made them available to you. In order to
get the kallisto results for all of these data, you can use the `aws s3 sync`
command provided below. Note that this will download ~ 8.2Gb of data to your
computer / Amazon instance.

```bash
cd /data
aws s3 sync s3://mbl.data/mapping/may may-kallisto
```

You will now have a directory structure that looks like this:

```bash
/data/may-kallisto
├── fish/
│   ├── drdgwt01/
│   │   ├── abundance.h5
│   │   ├── abundance.tsv
│   │   ├── kallisto.log
│   │   ├── pseudoalignments.bam
│   │   ├── pseudoalignments.bam.bai
│   │   └── run_info.json
│   ├── drdgwt02/
│   ├── ...
│   └── drkrwt15/
├── fly/
│   ├── dmneaohi01/
│   ├── ...
│   └── dmnewthi12/
├── mouse/
│   ├── mmchko02/
│   ├── ...
│   └── mmwpwt04/
┴
```

Which should be somewhat similar to the directory structure you generated
manually.

# Data Preparation

## Sample Annotation

To analyze data with sleuth, we need to generate a table that provides sample
level information for our data. Minimally this will be a three-column table
with the following columns:

* `"sample"`: the sample identifier. In our data, these are the directory names
  under the "organism trees" in the `may-kallisto` directory outlined above, eg.
  "drdgwt01", "drdgwt02", ...
* `"condition"`: a label for the "replicate group" (condition) the sample
  belongs in. For instance, in our mouse data we have samples from different
  "sources" (cheek, palate, trigeminal, and whisker_pad) and genotypes
  (widtype, and knockout). Reasonable entries for the condition column here
  would be:
     - cheek_knockout
     - cheek_wildtpe
     - palate_knockout
     - palate_wildtype
     - ...
* `"path"`: The path on the filesystem to the directory that holds the kallisto
  output for the sample, ie. in the example directory structure outlines above
  the `path` value for the `mmchko02` mouse sample would be:
  `/data/may-kallisto/mouse/mmchko02`

You can include any number of additional columns in this table that are used
to indicate different phenotypical data for each sample. You might, for
instance, choose to also just have a "genotype" column that simply includes
"knockout", or "wildtype" indicators (or name the gene that is knocked out, in
case you have a multiple knockout experiment).

**Your job is to now make this file** Feel free to use Excel or whatever tool
you feel most comfortable with.

The `mbl2018` R package provides a function that generates this function for
you:

```{r, message=FALSE, warning=FALSE}
# library(mbl2018)
devtools::load_all("/home/ubuntu/mbl2018/Rpkg")
library(ggplot2)
theme_set(theme_bw())
sample_info <- get_sample_annotation("mouse", dataset = "provided",
                                     for_kallisto = TRUE,
                                     kallisto_parent_dir = "/data/may-kallisto/mouse")
```

The first six lines of this table look like this:

```{r}
knitr::kable(head(sample_info, 6), row.names = FALSE)
```

You will also need a `data.frame` that tells sleuth which transcripts were
quantitated, and which genes they belong to.

These tables are provided on s3 here:

```bash
s3://mbl.data/referenes/<ORGANISM>/gene_table.csv
```

which you can download and load into R, but are also made availble from within
the `mbl2018` R package via the `get_gene_annotation()` function, which uses
R code to download the same file from S3 and loads it straight into your
session, like so:

```{r, message=FALSE, warning=FALSE}
mouse_tx_info <- get_transcript_annotation("mouse")
```

## Simple Sleuth Setup

We'll start by using sleuth in a simple scenario, which involves only analyzing
two-condition experiments, ie. "cheek_knockout" vs "cheek_wildtype"

Let's subset our `sample_info` table to only include the samples we want to
test:

```{r}
si <- subset(sample_info, condition %in% c("cheek_knockout", "cheek_wildtype"))
```

Now we can build a "Sleuth object" that holds the data for downstream analysis:

```{r}
so <- sleuth_prep(si, target_mapping = mouse_tx_info,
                  extra_bootstrap_summary = TRUE)
```
```{r}
so <- sleuth_fit(so, ~ condition, "full")
so <- sleuth_fit(so, ~ 1, "reduced")
so <- sleuth_lrt(so, "reduced", "full")
res <- sleuth_results(so, "reduced:full", "lrt", show_all = TRUE)
res <- arrange(res, pval)
```

## All mouse data

```{r}
smo <- sleuth_prep(sample_info, target_mapping = mouse_tx_info,
                   extra_bootstrap_summary = TRUE)
```

### PCA

```{r}
pp <- plot_pca(smo, color_by = "condition")
# ggplotly(
#   ggplot(pp$data, aes(PC1, PC2, color = condition, text = sample)) +
#     geom_point())


pp
```

Outer samples correspond to "mmchwt02" and "mmpako03" on the y axis,
and "mmchwt04" on the x.

## Analysis w/o outliers

```{r}
sir <- subset(sample_info, !sample %in% c("mmchwt02", "mmpako03", "mmchwt04"))
smr <- sleuth_prep(sir, target_mapping = mouse_tx_info,
                   extra_bootstrap_summary = TRUE)
```

```{r}
ppr <- plot_pca(smr, color_by = "condition")
ppr
```

smr <- sleuth_fit(smr, ~ condition, "full")
smr <- sleuth_fit(smr, ~ 1, "reduced")
smr <- sleuth_lrt(smr, "reduced", "full")
resr <- sleuth_results(smr, "reduced:full", "lrt", show_all = TRUE)
resr <- arrange(smr, pval)
```


